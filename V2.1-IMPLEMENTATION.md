# V2.1 Implementation Guide

## What's Implemented

The V2.1 plugin (`orchestrator.plugin.v2.1.ts`) fully implements context-aware multi-dimensional model selection based on real-world validation.

## Key Features

### 1. Per-Level Fallback Arrays ✅

Models can be configured as strings or arrays:

```typescript
// Single model (no fallback)
simple: "zai-coding-plan/glm-4.6"

// Fallback array (try in order)
complex: [
  "anthropic/claude-sonnet-4-5-20250929",  // Try first
  "zai-coding-plan/glm-4.6"                 // Fallback
]
```

**Implementation:**
- `recommendedModels: string[]` in `AnalysisResult`
- Supports both `string` and `string[]` in config
- Returns array of models for fallback support

### 2. Context-Aware Complexity Adjustment ✅

#### A. Plan Detection

Scans session context for plan indicators:
```typescript
planIndicators: ["step 1", "step 2", "- [ ]", "1."]
minStepsForReduction: 3  // Need 3+ steps
```

**Effect:** If plan found → reduce complexity by 1 level

#### B. Subtask Detection

Checks prompt for subtask indicators:
```typescript
subtaskIndicators: [
  "implement step",
  "from the plan",
  "next todo"
]
```

**Effect:** If subtask → reduce complexity by 1 level

#### C. Context Size Adjustment

```typescript
contextSize: {
  smallContextThreshold: 50000,   // <50K: reduce complexity
  largeContextThreshold: 100000,  // >100K: raise complexity
}
```

**Logic:**
- **<50K tokens**: Small context → focused task → **reduce** complexity
- **50-100K tokens**: Normal → **no change**
- **>100K tokens**: Large context → multi-faceted → **raise** complexity

### 3. Fine-Grained Task Types ✅

Seven task types with distinct handling:

1. **`coding-simple`**: Implementation with existing plan
2. **`coding-complex`**: Architectural/critical work
3. **`planning`**: Design and strategy
4. **`debugging`**: Error analysis
5. **`review`**: Code review
6. **`documentation`**: Docs and comments
7. **`general`**: Fallback for questions

### 4. Context Tracking ✅

Tracks context size throughout session:
```typescript
let contextTokens: number = 0;

// Update on every message
if (event.type === "message.create") {
  contextTokens += estimateTokenCount(event.properties.content);
}
```

### 5. Session Context Integration ✅

Fetches recent messages for plan detection:
```typescript
const messages = await client.session.messages({ path: { id: currentSessionId } });
sessionContext = messages.slice(-5)  // Last 5 messages
  .map(msg => msg.parts?.map(p => p.text).join("\n"))
  .join("\n");
```

## Real-World Example

### Your Kimeno Migration

**Phase 1: Planning (auto-performance agent)**

```
Input:
  Prompt: "Plan migration of Kimeno invoice admin to unified bizonylat"
  Context: 0 tokens (new session)
  Agent: auto-performance

Analysis:
  Task Type: planning (detected "plan", "migration")
  Base Complexity: complex (keywords: "migration", "unified")
  Context Adjustment: <50K → reduce to medium
  Strategy: performance-optimized
  Model Selection: performance-optimized.planning.medium
  Result: anthropic/claude-sonnet-4-5-20250929

Output:
  - Detailed plan created
  - Context grows to ~50K tokens
  - Plan has 4+ steps (triggers plan detection)
```

**Phase 2: Implementation (auto-optimized agent)**

```
Input:
  Prompt: "Implement step 1 from the plan: Replace data fetching"
  Context: 50K tokens (from planning)
  Agent: auto-optimized

Analysis:
  Task Type: coding-simple (detected "implement step", "from the plan")
  Base Complexity: medium (file modifications)

  Context Adjustments:
    1. Plan detected (4 steps in context): medium → simple
    2. Subtask detected ("step 1"): already simple
    3. Context size 50K: no adjustment (normal range)

  Final Complexity: simple
  Strategy: cost-optimized
  Model Selection: cost-optimized.coding-simple.simple
  Result: zai-coding-plan/glm-4.6

Output:
  - Model: GLM 4.6 (FREE)
  - Successful implementation
  - 0 errors
```

## Usage

### Installation

```bash
# Use V2.1 plugin
cp orchestrator.plugin.v2.1.ts ~/.config/opencode/plugin/orchestrator.plugin.ts

# Use V2.1 config
cp orchestrator.config.v2.1.md ~/.config/opencode/orchestrator.config.md

# Install dependencies
npm install yaml
```

### Testing the Custom Tool

```typescript
// In OpenCode, use the custom tool
{
  "tool": "checkComplexity",
  "args": {
    "prompt": "Implement step 3 from the task list",
    "strategy": "cost-optimized",
    "context": "## Plan\n1. Create model\n2. Add endpoint\n3. Add tests\n4. Deploy"
  }
}

// Returns:
{
  "strategy": "cost-optimized",
  "taskType": "coding-simple",
  "baseComplexity": "medium",
  "finalComplexity": "simple",
  "primaryModel": "zai-coding-plan/glm-4.6",
  "fallbackModels": [],
  "contextAdjustments": [
    "Plan detected: medium → simple",
    "Subtask detected: reduced to simple"
  ],
  "reasoning": [
    "Task type: coding-simple",
    "Base complexity: medium",
    "Detailed plan exists in context, reduced complexity",
    "Implementing subtask from plan, reduced complexity",
    "Selected from cost-optimized.coding-simple.simple"
  ]
}
```

## Configuration Examples

### Cost-Optimized with Fallbacks

```yaml
strategies:
  cost-optimized:
    coding-simple:
      simple: zai-coding-plan/glm-4.6  # No fallback
      medium: zai-coding-plan/glm-4.6  # No fallback
      complex:  # Fallback array
        - anthropic/claude-sonnet-4-5-20250929
        - zai-coding-plan/glm-4.6
      advanced:  # Multi-tier fallback
        - openai/gpt-5-codex-high
        - anthropic/claude-sonnet-4-5-20250929
        - zai-coding-plan/glm-4.6
```

### Performance-Optimized

```yaml
strategies:
  performance-optimized:
    coding-simple:
      simple: anthropic/claude-haiku-4-20250514
      medium: anthropic/claude-haiku-4-20250514
      complex:
        - anthropic/claude-sonnet-4-5-20250929
        - anthropic/claude-haiku-4-20250514
      advanced:
        - anthropic/claude-sonnet-4-5-20250929
```

## Output Format

### Normal Logging

```
[Orchestrator V2.1] Task Analysis:
  Strategy: cost-optimized
  Task Type: coding-simple
  Base Complexity: medium
  Context Adjustments:
    - Plan detected: medium → simple
    - Subtask detected: reduced to simple
    - Normal context (50K tokens), no adjustment
  Final Complexity: simple
  Model: zai-coding-plan/glm-4.6
  Reasoning:
    - Task type: coding-simple
    - Base complexity: medium
    - Detailed plan exists in context, reduced complexity
    - Implementing subtask from plan, reduced complexity
    - Selected from cost-optimized.coding-simple.simple
```

### Verbose Logging

Includes all events and detailed analysis steps.

## Implementation Details

### Complexity Reduction Logic

```typescript
function reduceComplexity(complexity: Complexity): Complexity {
  const levels: Complexity[] = ["simple", "medium", "complex", "advanced"];
  const index = levels.indexOf(complexity);
  return index > 0 ? levels[index - 1] : complexity;
}

// Examples:
reduceComplexity("advanced") → "complex"
reduceComplexity("complex")  → "medium"
reduceComplexity("medium")   → "simple"
reduceComplexity("simple")   → "simple" (can't reduce further)
```

### Context Size Tracking

```typescript
// Initialize on session start
let contextTokens: number = 0;

// Track on every message
event.type === "message.create"
  → contextTokens += estimateTokenCount(content)

// Use in analysis
if (contextTokens < 50000) {
  finalComplexity = reduceComplexity(finalComplexity);
} else if (contextTokens > 100000) {
  finalComplexity = raiseComplexity(finalComplexity);
}
```

### Plan Detection

```typescript
function detectPlan(context: string, config: PlanConfig): boolean {
  let stepCount = 0;

  for (const indicator of config.planIndicators) {
    const matches = context.match(new RegExp(indicator, "gi"));
    if (matches) {
      stepCount += matches.length;
    }
  }

  return stepCount >= config.minStepsForReduction;
}
```

## Benefits

### 1. Matches Real Workflow ✅

Your actual experience validated:
- Plan with GPT-5 Codex (complex planning)
- Implement with GLM 4.6 (simple with plan)
- 50K context enables cheaper model

### 2. Cost Savings ✅

```
Without V2.1:
  Medium coding → Haiku ($)

With V2.1 (with plan):
  Medium coding + plan detected → simple → GLM (FREE)

Savings: 100% for planned implementation work
```

### 3. Context Awareness ✅

```
Small context (20K):
  "Refactor auth" (complex) → reduce → medium → GLM

Normal context (70K):
  "Add feature" (medium) → no change → medium → GLM

Large context (120K):
  "Add email" (medium) → raise → complex → Sonnet
```

### 4. Transparency ✅

Every decision is logged with reasoning:
- What was detected
- What adjustments were made
- Why the model was selected
- Fallback chain if applicable

## Migration from V2

1. Replace plugin: `orchestrator.plugin.v2.ts` → `orchestrator.plugin.v2.1.ts`
2. Update config: Add `contextAware` section
3. Update models: Use arrays for fallbacks
4. Test with verbose logging

## Troubleshooting

### Plan Not Detected

Check indicators in config:
```yaml
planAwareness:
  planIndicators:
    - "step 1"
    - "1."
    - "- [ ]"
  minStepsForReduction: 3  # Lower if needed
```

### Wrong Complexity

Enable verbose logging:
```yaml
logLevel: verbose
```

Check context adjustments in output.

### Fallback Not Working

Verify array syntax:
```yaml
# Correct
complex:
  - model-a
  - model-b

# Incorrect
complex: [model-a, model-b]  # YAML array syntax works too
```

## Summary

V2.1 implements **context-aware multi-dimensional selection** based on your real-world success:

✅ Per-level fallback arrays
✅ Plan detection and reduction
✅ Subtask detection
✅ Context-size awareness
✅ Fine-grained task types
✅ Session context integration
✅ Transparent logging

**Result:** Plan with premium models, implement with cheaper models when plan exists.
